---
layout: page
title:  Groups of Special-Equivalent Strings-out
permalink: /s893
---
You are given an array `words` of strings. A move consists of choosing any two even indexed characters of a string and swapping them, or choosing any two odd indexed characters of a string and swapping them.

Two strings are special-equivalent if after any number of moves, they are equal. For example, "abcde" and "adcbe" are special-equivalent because we can swap the 'b' and 'd' which are both at odd indices to make the strings equal.

Return the number of groups of special-equivalent strings from the input array `words`.

### Example:
```python
Input: ["abcd","cdab","cbad","xyzz","zzxy","zzyx"]
Output: 3
Explanation: 
One group is ["abcd", "cdab", "cbad"], since they are all special-equivalent.
The other two groups are ["xyzz", "zzxy"] and ["zzyx"].
```

### Constraints:
1. 1 <= words.length <= 1000
2. 1 <= words[i].length <= 20
3. All `words[i]` have the same length.
4. All `words[i]` consist of only lowercase English letters.

## Clarifying Questions
1. **Are all given words have the same length in the input array?**
   - Yes, as specified in the constraints.

2. **Is there any specific performance constraint or maximum length of strings we should consider?**
   - Given the constraints, we can expect up to 1000 words each of up to length 20 which should be manageable within the given constraints.

## Strategy
1. **Character Classification:** 
   - Separate each string into characters at even and odd indices.
   - Sort the characters at even indices and odd indices separately. 

2. **Normalization:** 
   - Combine the sorted even indices and sorted odd indices into a tuple to create a normalized representation of each string.

3. **Set Utilization:** 
   - Use a set to keep track of all unique normalized tuples. The size of this set at the end will be the number of unique groups.

## Code
```python
def numSpecialEquivGroups(words):
    def normalize(word):
        even_chars = sorted(word[0::2])
        odd_chars = sorted(word[1::2])
        return (tuple(even_chars), tuple(odd_chars))
    
    normalized_set = set(normalize(word) for word in words)
    return len(normalized_set)

# Example Usage
words = ["abcd", "cdab", "cbad", "xyzz", "zzxy", "zzyx"]
print(numSpecialEquivGroups(words))  # Output: 3
```

## Time Complexity
Let's analyze the time complexity:
- **Normalization step:** 
  - Separating even and odd index characters takes O(n) time for each word where `n` is the length of the word. 
  - Sorting the characters takes O(n log n).
- **Overall for each word:** 
  - The overall time complexity for normalizing one word is O(n log n).

- **Considering all words:**
  - Processing all words is O(m * n log n) where `m` is the number of words and `n` is the length of each word.

- **Storage:**
  - The space complexity arises from storing up to `m` tuples in the set, each containing up to `n` characters, which is O(m * n). 

Thus, the final time complexity is O(m * n log n) and the space complexity is O(m * n).
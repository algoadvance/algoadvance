
---
layout: page
title:  Increment Submatrices by One-out
permalink: /s2536
---

You are given a 2D integer array `queries` where `queries[i] = [row1i, col1i, row2i, col2i]`. For each `query`, you have to increment all the submatrix elements within the rectangle defined by `(row1i, col1i)` to `(row2i, col2i)` by one.

Return the resulting matrix after processing all the queries. Assume the matrix initially contains only zeros and has sufficient size to cover all the increment operations.

## Clarifying Questions

1. **Matrix Size:** 
   - Is the size of the matrix provided, or do we need to infer it from the queries?
   - Do we need to handle matrices with very large dimensions within memory constraints?

2. **Input Constraints:** 
   - What are the possible range values for the rows and columns?
   - How large can the list of queries be?

3. **Output Requirements:**
   - Should the returned matrix exactly cover the area spanned by the queries, or can it be larger?
   - Is there an upper limit on the values inside the matrix after all operations?

## Strategy

We can solve this efficiently by using a 2D prefix sum array to reduce the time complexity of range updates. Hereâ€™s the step-by-step breakdown:

1. **Initialize the Matrix:** Create a matrix `mat` filled with zeros with dimensions slightly larger than the maximum `row` and `col` values encountered in the queries.

2. **Apply Increment Operations using Difference Array Technique:**
   - For each query `(row1, col1, row2, col2)`, we will adjust the corners of the matrix to mark the incremental effects:
     - +1 at `(row1, col1)`
     - -1 at `(row1, col2 + 1)`
     - -1 at `(row2 + 1, col1)`
     - +1 at `(row2 + 1, col2 + 1)`

3. **Compute the Final Values:**
   - Convert the difference matrix to the actual result matrix by calculating prefix sums row-wise and column-wise.

4. **Extract the Submatrix:** Based on the maximum row and column indices from the queries, extract the valid part of the matrix to return.

## Code

```python
def incrementSubmatrices(n: int, m: int, queries: List[List[int]]) -> List[List[int]]:
    mat = [[0] * (m + 1) for _ in range(n + 1)]

    for row1, col1, row2, col2 in queries:
        mat[row1][col1] += 1
        if col2 + 1 <= m:
            mat[row1][col2 + 1] -= 1
        if row2 + 1 <= n:
            mat[row2 + 1][col1] -= 1
        if row2 + 1 <= n and col2 + 1 <= m:
            mat[row2 + 1][col2 + 1] += 1

    # Create result matrix by calculating prefix sums
    for i in range(n):
        for j in range(m):
            if j > 0:
                mat[i][j] += mat[i][j - 1]

    for j in range(m):
        for i in range(n):
            if i > 0:
                mat[i][j] += mat[i - 1][j]

    # Extract the valid part of the matrix to return (n x m)
    result = [row[:m] for row in mat[:n]]
    return result
```

## Time Complexity

The approach taken offers an efficient time complexity:

1. **Initialization:** Creating the matrix is \(O(n \times m)\).
2. **Applying Queries:** Each query updating the corners is \(O(1)\), so total for \(q\) queries is \(O(q)\).
3. **Prefix Sum Calculation:** Calculating prefix sums is \(O(n \times m)\).

Thus, the overall time complexity is \(O(n \times m + q)\), where \(q\) is the number of queries, and \(n\) and \(m\) are the dimensions of the matrix.
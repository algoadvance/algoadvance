
---
layout: page
title:  Online Majority Element In Subarray-out
permalink: /s1157
---
Design a class `MajorityChecker` which has the following functions:

- `MajorityChecker(int[] arr)`: Initializes the object with the given array `arr`.
- `int query(int left, int right, int threshold)`: Returns the element that occurs at least `threshold` times in the subarray `arr[left...right]`. If no such element exists, return `-1`.

### Clarifying Questions
1. **What is the range of the array size and the number of queries?**
   - This helps understand the efficiency requirements.
2. **What are the possible values for the elements in the array?**
   - This clarifies if we need to handle specific ranges, e.g., only positive integers.
3. **Is threshold always guaranteed to be valid?**
   - This ensures that we know if the threshold will always be a positive integer.

### Strategy
To efficiently handle multiple queries, we can employ a combination of techniques:

1. **Segment Trees:** To assist with range queries efficiently.
2. **HashMaps and Preprocessing:** To quickly determine the count of each element within a range.

#### Step-by-step Approach:

1. **Preprocessing:** 
   - Create a data structure that maintains the counts of each element at different positions.
   - Use a hashmap where the key is the element and the value is a list of positions where this element appears.

2. **Segment Tree:**
   - Build a segment tree where each node stores the majority element and its count in that range. 
   - A helper function to merge the results from the segment tree nodes.

3. **Query:**
   - Using the segment tree, get the candidate majority element for the range.
   - Verify if it meets the threshold by counting its appearances in the desired range using our preprocessed data.

### Code

Here's the implementation in Python:

```python
from collections import defaultdict
import bisect

class MajorityChecker:

    def __init__(self, arr):
        self.arr = arr
        self.pos = defaultdict(list)
        
        for i, num in enumerate(arr):
            self.pos[num].append(i)
        
        self.seg_tree = [None] * (4 * len(arr))
        self.__build_seg_tree(arr, 0, 0, len(arr) - 1)

    def __build_seg_tree(self, arr, tree_idx, l, r):
        if l == r:
            self.seg_tree[tree_idx] = (arr[l], 1)
            return
        
        mid = (l + r) // 2
        self.__build_seg_tree(arr, 2 * tree_idx + 1, l, mid)
        self.__build_seg_tree(arr, 2 * tree_idx + 2, mid + 1, r)
        self.seg_tree[tree_idx] = self.__merge(self.seg_tree[2 * tree_idx + 1], self.seg_tree[2 * tree_idx + 2])
    
    def __merge(self, left, right):
        if left[0] == right[0]:
            return (left[0], left[1] + right[1])
        elif left[1] > right[1]:
            return (left[0], left[1] - right[1])
        else:
            return (right[0], right[1] - left[1])
    
    def __query_seg_tree(self, tree_idx, l, r, ql, qr):
        if ql > r or qr < l:
            return (None, 0)
        
        if ql <= l and qr >= r:
            return self.seg_tree[tree_idx]
        
        mid = (l + r) // 2
        left_result = self.__query_seg_tree(2 * tree_idx + 1, l, mid, ql, qr)
        right_result = self.__query_seg_tree(2 * tree_idx + 2, mid + 1, r, ql, qr)
        return self.__merge(left_result, right_result)
    
    def query(self, left, right, threshold):
        candidate, _ = self.__query_seg_tree(0, 0, len(self.arr) - 1, left, right)
        
        if candidate is None:
            return -1
        
        l_pos = bisect.bisect_left(self.pos[candidate], left)
        r_pos = bisect.bisect_right(self.pos[candidate], right)
        
        if r_pos - l_pos >= threshold:
            return candidate
        else:
            return -1
```

### Time Complexity
- **Preprocessing:** `O(n log n)` for segment tree building and `O(n)` for position mapping.
- **Query:** `O(log n)` for segment tree traversal and `O(log n)` for binary search, making it overall `O(log n)` per query in the best case of constant-time list operations.

By segmenting into preprocessing and efficient querying, the solution becomes viable for large datasets and many queries.
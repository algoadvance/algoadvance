---
layout: page
title: leetcode 1605. Find Valid Matrix Given Row and Column Sums
permalink: /s1605-java
---
[Leetcode 1605. Find Valid Matrix Given Row and Column Sums full problem statement](https://algoadvance.github.io/algoadvance/l1605)
### Problem Statement
You are given two arrays `rowSum` and `colSum` with non-negative integers where `rowSum[i]` is the sum of the elements in the `i-th` row and `colSum[j]` is the sum of the elements in the `j-th` column of a 2D matrix. Your task is to find any matrix of non-negative integers that satisfy both `rowSum` and `colSum`.

### Clarifying Questions
- Will the input arrays `rowSum` and `colSum` always have a non-empty positive sum that allows for the construction of a valid matrix?
  - **Yes**, it is guaranteed that there is at least one solution.
- Can the elements of the output matrix be any non-negative integer, or do they have an upper bound?
  - The elements can be any non-negative integers.

### Strategy
We can use a greedy approach to solve this problem:

1. **Initialize** a matrix `m` with dimensions `[len(rowSum)] x [len(colSum)]` filled with zeros.
2. **Iterate** through each cell in the matrix, attempting to satisfy the `rowSum` and `colSum` constraints:
   - For each cell `(i, j)`, place the lesser of the remaining `rowSum[i]` and `colSum[j]` in the matrix cell `m[i][j]`.
   - Deduct this placed value from both `rowSum[i]` and `colSum[j]`.
3. **Continue** this process until the end of the matrix is reached.
4. **Return** the constructed matrix.

### Code
Here's the Java implementation of the described strategy:

```java
public class Solution {
    public int[][] restoreMatrix(int[] rowSum, int[] colSum) {
        int numRows = rowSum.length;
        int numCols = colSum.length;
        int[][] matrix = new int[numRows][numCols];

        for (int i = 0; i < numRows; i++) {
            for (int j = 0; j < numCols; j++) {
                // Find the minimum value we can use to satisfy this position
                int val = Math.min(rowSum[i], colSum[j]);
                matrix[i][j] = val;
                
                // Deduct this value from the respective row sum and column sum
                rowSum[i] -= val;
                colSum[j] -= val;
            }
        }

        return matrix;
    }
}
```

### Time Complexity
The time complexity of this solution is \(O(m \times n)\), where \(m\) is the number of rows and \(n\) is the number of columns. This is because we are iterating over each cell in the matrix exactly once.

### Explanation of Code
1. We define the dimensions of the matrix and initialize it with zeros.
2. We then loop through each row and column, filling in the matrix with the minimum possible value that satisfies both the current row and column constraints.
3. After placing a value in the matrix, we decrement the corresponding values in `rowSum` and `colSum` to reflect the updated sums.
4. Finally, we return the constructed matrix.
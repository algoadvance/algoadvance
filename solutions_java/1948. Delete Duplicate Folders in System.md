---
layout: page
title: leetcode 1948. Delete Duplicate Folders in System
permalink: /s1948-java
---
[Leetcode 1948. Delete Duplicate Folders in System](https://algoadvance.github.io/algoadvance/l1948)
### Problem Statement

You are given a file system represented as a list of paths, where each path is an array of strings representing the nested folders inside that path. Your task is to delete all the duplicated folders, and return the file system after removing them.

Two folders are considered duplicates if they contain the same subfolders (the order of the subfolders does not matter). The same applies recursively to their sub-subfolders.

After removing the duplicate folders, return the paths list in any order.

### Example
```java
Input: paths = [["a"], ["c"], ["d"], ["a","b"], ["c","b"], ["d","a"]]
Output: [[],["c","b"],["a"],["d"],["a","b"],["d","a"]]
```

### Clarifying Questions

1. **Are all folder names guaranteed to be unique within a path?**
   - **Answer: Yes, within a single path, folder names are unique.**

2. **What is the maximum depth for any given path?**
   - **Answer: Folder paths should not exceed a depth of 200.**

3. **Can a folder name in a path be duplicated at different levels?**
   - **Answer: Yes, within different paths, folder names can be repeated.**

4. **What is the maximum number of paths?**
   - **Answer: The number of paths will not exceed 2000.**

### Strategy

1. **Construct a Trie-like Structure:**
   - First, build a Trie (prefix tree) to represent the folder structure.
  
2. **Serialize Subtrees:**
   - Implement a way to serialize each folder's subtree.
   - Serialization can help in determining duplicate folders by comparing serialized forms.

3. **Mark Duplicates:**
   - Use a map to count the frequency of each serialized subtree.
   - If any subtree has a frequency greater than 1, mark those subtrees as duplicates.

4. **Reconstruct Paths:**
   - Reconstruct the path list from the Trie excluding marked folders.

### Code

Here's the Java implementation to solve the problem:

```java
import java.util.*;

public class Solution {
    static class TrieNode {
        Map<String, TrieNode> children = new HashMap<>();
        String name;
        boolean toDelete = false;
    }
    
    private String serialize(TrieNode node, Map<String, List<TrieNode>> subtreeMap) {
        if (node.children.isEmpty()) return "";
        
        List<String> serializedChildren = new ArrayList<>();
        for (TrieNode child : node.children.values()) {
            serializedChildren.add(child.name + "(" + serialize(child, subtreeMap) + ")");
        }
        Collections.sort(serializedChildren);
        String serialized = String.join(",", serializedChildren);
        
        subtreeMap.computeIfAbsent(serialized, k -> new ArrayList<>()).add(node);
        return serialized;
    }
    
    private void markDuplicates(Map<String, List<TrieNode>> subtreeMap) {
        for (List<TrieNode> nodes : subtreeMap.values()) {
            if (nodes.size() > 1) {
                for (TrieNode node : nodes) {
                    node.toDelete = true;
                }
            }
        }
    }
    
    private void collectPaths(TrieNode node, List<List<String>> result, List<String> currentPath) {
        if (node.toDelete) return;
        
        if (!node.name.isEmpty()) currentPath.add(node.name);
        
        if (!currentPath.isEmpty()) result.add(new ArrayList<>(currentPath));
        
        for (TrieNode child : node.children.values()) {
            collectPaths(child, result, currentPath);
        }
        
        if (!currentPath.isEmpty()) currentPath.remove(currentPath.size() - 1);
    }
    
    public List<List<String>> deleteDuplicateFolder(List<List<String>> paths) {
        TrieNode root = new TrieNode();
        root.name = "";
        
        // Build Trie
        for (List<String> path : paths) {
            TrieNode current = root;
            for (String folder : path) {
                current.children.putIfAbsent(folder, new TrieNode());
                current = current.children.get(folder);
                current.name = folder;
            }
        }
        
        // Serialize subtrees
        Map<String, List<TrieNode>> subtreeMap = new HashMap<>();
        serialize(root, subtreeMap);
        
        // Mark duplicates
        markDuplicates(subtreeMap);
        
        // Collect non-duplicate paths
        List<List<String>> result = new ArrayList<>();
        collectPaths(root, result, new ArrayList<>());
        
        return result;
    }
    
    public static void main(String[] args) {
        Solution sol = new Solution();
        List<List<String>> paths = Arrays.asList(
            Arrays.asList("a"), Arrays.asList("c"), Arrays.asList("d"), 
            Arrays.asList("a", "b"), Arrays.asList("c", "b"), Arrays.asList("d", "a")
        );
        System.out.println(sol.deleteDuplicateFolder(paths));
    }
}
```

### Time Complexity

- **Building the Trie:** `O(p * m)`, where `p` is the number of paths and `m` is the average length of each path.  
- **Serialization:** `O(n)`, where `n` is the total number of nodes in the Trie.  
- **Marking Duplicates:** `O(n)`, as it involves iterating over the subtree map.  
- **Collecting Paths:** `O(n)`, to traverse the Trie and collect non-duplicate paths.

This yields an overall complexity of `O(p * m + n)`, which is efficient given the constraints (2000 paths and depth up to 200).

The space complexity is also manageable as we use a Trie structure and additional maps for serialization checks.


### Cut your prep time in half and DOMINATE your interview with [AlgoAdvance AI](https://algoAdvance.com)

- Got blindsided by a question you didn't expect?

- Spend too much time studying?

- Or simply don't have the time to go over all 3000 questions?


---
layout: page
title: leetcode 1948. Delete Duplicate Folders in System
permalink: /s1948-cpp
---
[Leetcode 1948. Delete Duplicate Folders in System](https://algoadvance.github.io/algoadvance/l1948)
### Problem Statement
You are given a set of folders in a file system represented by a list of paths, where each path is a string that represents the hierarchical structure of the folder. Your task is to delete all duplicate folders and return the remaining folders in the same format. Two folders are considered duplicate if they contain the same set of subfolders and each set of subfolders is identical in structure.

### Clarifying Questions
1. **Input Format:**
   - Is the input path list guaranteed to be non-empty?
   - Can the folder names contain any special characters or whitespace?
   
2. **Output Format:**
   - Should the output be sorted in any particular order?
  
3. **Constraints:**
   - What is the maximum depth of the folder structure?
   - What is the maximum number of folders in the system?

### Strategy
1. **Parse the Folder Paths:**
   - First, we need to parse the given list of paths to construct a tree-like structure representing the file system.

2. **Hash Subtree Structures:**
   - We will use a depth-first traversal to create a unique hash for the structure of each subtree. This will help us identify duplicate structures.

3. **Mark Duplicates:**
   - Use a hash table to keep track of all subtree structures and their frequencies.
   - Traverse the tree again to mark subtrees that appear more than once.

4. **Delete Duplicates:**
   - Traverse the tree a final time to construct a list of paths that represent the remaining folders after removing duplicates.

### Code Implementation

```cpp
#include <iostream>
#include <vector>
#include <unordered_map>
#include <unordered_set>
#include <sstream>
#include <string>
#include <algorithm>

using namespace std;

struct TreeNode {
    string name;
    unordered_map<string, TreeNode*> children;
    
    TreeNode(string name) : name(name) {}
};

class Solution {
public:
    vector<vector<string>> deleteDuplicateFolder(vector<vector<string>>& paths) {
        TreeNode* root = new TreeNode("");
        
        // Build the tree
        for (const auto& path : paths) {
            TreeNode* current = root;
            for (const auto& folder : path) {
                if (!current->children.count(folder)) {
                    current->children[folder] = new TreeNode(folder);
                }
                current = current->children[folder];
            }
        }
        
        // Map to store serialized subtree strings
        unordered_map<string, int> subtreeMap;
        unordered_set<TreeNode*> toDelete;
        
        // Generate a hash for subtrees
        serializeSubtree(root, subtreeMap, toDelete);
        
        // Collect the result paths
        vector<vector<string>> result;
        vector<string> currentPath;
        collectResult(root, result, currentPath, toDelete);
        
        return result;
    }
    
private:
    string serializeSubtree(TreeNode* node, unordered_map<string, int>& subtreeMap, unordered_set<TreeNode*>& toDelete) {
        if (!node) return "";
        
        vector<string> parts;
        for (auto& [name, child] : node->children) {
            parts.push_back(name + "(" + serializeSubtree(child, subtreeMap, toDelete) + ")");
        }
        sort(parts.begin(), parts.end());
        string serialized = accumulate(parts.begin(), parts.end(), string());
        
        if (!node->name.empty()) { // Skip the root
            subtreeMap[serialized]++;
            if (subtreeMap[serialized] > 1) {
                toDelete.insert(node);
            }
        }
        
        return serialized;
    }
    
    void collectResult(TreeNode* node, vector<vector<string>>& result, vector<string>& currentPath, unordered_set<TreeNode*>& toDelete) {
        if (!node || toDelete.count(node)) return;
        
        if (!node->name.empty()) { // Skip the root
            currentPath.push_back(node->name);
            result.push_back(currentPath);
        }
        
        for (auto& [name, child] : node->children) {
            collectResult(child, result, currentPath, toDelete);
        }
        
        if (!node->name.empty()) { // Skip the root
            currentPath.pop_back();
        }
    }
};
```

### Time Complexity
The time complexity mainly depends on the number of folders \( N \) and the maximum depth \( D \). 

1. **Building the Tree:** \( O(N \times D) \)
2. **Serializing Subtrees:** \( O(N \times D \log D) \) - Sorting subtrees.
3. **Constructing Result Paths:** \( O(N \times D) \)

Overall, the time complexity is \( O(N \times D \log D) \).

This solution ensures that we track and eliminate duplicate folder structures efficiently by creating a unique hash for each subtree, using serialization and depth-first search traversal techniques.


### Cut your prep time in half and DOMINATE your interview with [AlgoAdvance AI](https://algoAdvance.com)

- Got blindsided by a question you didn't expect?

- Spend too much time studying?

- Or simply don't have the time to go over all 3000 questions?


---
layout: page
title: leetcode 126. Word Ladder II
permalink: /s126-cpp
---
[Leetcode 126. Word Ladder II](https://algoadvance.github.io/algoadvance/l126)
## Problem Statement

**Word Ladder II** (Problem #126 on LeetCode)

Given two words, `beginWord` and `endWord`, and a dictionary's word list, find all the shortest transformation sequences from `beginWord` to `endWord`, such that:

1. Only one letter can be changed at a time.
2. Each transformed word must exist in the word list.

Return all possible shortest transformation sequences. If there is no such transformation sequence, return an empty list.

**Note:**

- The word list contains `beginWord` and `endWord`.
- Each word in the transformation sequence has to be the same length.
- All words in the word list are unique.
- You may assume no duplicates in the word list.
- You may assume `beginWord` and `endWord` are non-empty and are composed of lowercase letters only.

**Example 1:**

    Input:
    beginWord = "hit",
    endWord = "cog",
    wordList = ["hot","dot","dog","lot","log","cog"]

    Output:
    [
      ["hit","hot","dot","dog","cog"],
      ["hit","hot","lot","log","cog"]
    ]

**Example 2:**

    Input:
    beginWord = "hit",
    endWord = "cog",
    wordList = ["hot","dot","dog","lot","log"]

    Output: []

    Explanation: The endWord "cog" is not in wordList, therefore no possible transformation.

## Clarifying Questions

1. Can the beginWord be part of the wordList?
   - No, the beginWord does not need to be part of the wordList.
   
2. What should be the case when endWord is not in the wordList?
   - Return an empty list if endWord is not part of wordList.

3. Are all words of the same length?
   - Yes, all words, including beginWord and endWord are of the same length.

## Strategy

1. **Breadth-First Search (BFS)**: 
   - Use BFS to find the shortest transformation sequences.
   - Implement BFS to explore the word transformations at each level.
   
2. **Backtracking to find all Paths**:
   - Maintain a path map to store the predecessors for each word.
   - Backtrack from the endWord to the startWord using the path map to gather all valid transformations.

3. **Optimization**:
   - Use a queue to keep track of current words during BFS.
   - A set to keep track of visited words to avoid revisits.

4. **Bidirectional BFS** (advanced technique, optional):
   - This can be used to optimize by searching from both ends.

## Code

```cpp
#include <iostream>
#include <vector>
#include <unordered_set>
#include <unordered_map>
#include <queue>

using namespace std;

class Solution {
public:
    vector<vector<string>> findLadders(string beginWord, string endWord, vector<string>& wordList) {
        unordered_set<string> wordSet(wordList.begin(), wordList.end());
        vector<vector<string>> result;
        unordered_map<string, vector<string>> adjList;
        
        if (wordSet.find(endWord) == wordSet.end()) {
            return result;  // endWord not in list
        }
        
        // BFS to find the shortest path length
        queue<string> toVisit;
        toVisit.push(beginWord);
        unordered_map<string, int> distMap;
        distMap[beginWord] = 0;
        
        while (!toVisit.empty()) {
            string word = toVisit.front();
            toVisit.pop();
            
            string current = word;
            for (int i = 0; i < word.size(); ++i) {
                char originalChar = word[i];
                for (char c = 'a'; c <= 'z'; ++c) {
                    word[i] = c;
                    if (wordSet.find(word) != wordSet.end()) {
                        if (distMap.find(word) == distMap.end()) {
                            distMap[word] = distMap[current] + 1;
                            toVisit.push(word);
                        }
                        if (distMap[word] == distMap[current] + 1) {
                            adjList[word].push_back(current);
                        }
                    }
                }
                word[i] = originalChar;
            }
        }
        
        vector<string> path;
        backtrack(result, path, endWord, beginWord, adjList);
        return result;
    }

private:
    void backtrack(vector<vector<string>>& result, vector<string>& path, const string& word, const string& beginWord,
                   unordered_map<string, vector<string>>& adjList) {
        if (word == beginWord) {
            path.push_back(word);
            vector<string> validPath(path.rbegin(), path.rend());
            result.push_back(validPath);
            path.pop_back();
            return;
        }
        
        path.push_back(word);
        for (auto& prevWord : adjList[word]) {
            backtrack(result, path, prevWord, beginWord, adjList);
        }
        path.pop_back();
    }
};

int main() {
    Solution sol;
    vector<string> wordList = {"hot","dot","dog","lot","log","cog"};
    string beginWord = "hit";
    string endWord = "cog";
    vector<vector<string>> result = sol.findLadders(beginWord, endWord, wordList);
    
    for (const auto& seq : result) {
        for (const auto& word : seq) {
            cout << word << " ";
        }
        cout << endl;
    }
    
    return 0;
}
```

## Time Complexity

- **BFS Step**: Exploring each of the words takes O(N * 26) operations per word (where N is the number of words in the word list), and there's an additional factor for each level explored, so total operation roughly O(N * M * 26) where M is the length of the word.
- **Backtracking Step**: For backtracking to get all paths, in the worst case would be O(V + E) (V vertices/nodes and E edges), but this can be complex if the number of sequences grows exponentially in practice.

Combining both, you are looking at potentially high complexity due to the backtracking step, but it is mitigated by the limitations on the input size generally imposed in competitive programming environments.


### Cut your prep time in half and DOMINATE your interview with [AlgoAdvance AI](https://algoAdvance.com)

- Got blindsided by a question you didn't expect?

- Spend too much time studying?

- Or simply don't have the time to go over all 3000 questions?


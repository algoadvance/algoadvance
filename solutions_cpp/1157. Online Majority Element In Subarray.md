---
layout: page
title: leetcode 1157. Online Majority Element In Subarray
permalink: /s1157-cpp
---
[Leetcode 1157. Online Majority Element In Subarray](https://algoadvance.github.io/algoadvance/l1157)
### Problem Statement:
Design a data structure that can efficiently answer queries about the majority element in a given subarray. The majority element in a subarray is the element that appears more than half the times in that subarray.

Implement the `MajorityChecker` class:
- `MajorityChecker(int[] arr)` initializes the instance of the class with the given array.
- `int query(int left, int right, int threshold)` returns the majority element in the subarray `arr[left...right]` that appears at least `threshold` times. If no such element exists, return `-1`.

### Clarifying Questions:
1. **What are the constraints on the size of the array and the values within it?**
   - **Array size (`n`)**: `1 <= arr.length <= 2 * 10^4`
   - **Element values**: Each element is between `1` and `2 * 10^4` (inclusive).
2. **How many queries can we expect?**
   - We can assume a large number of queries to justify the need for a data structure that efficiently handles them.
3. **Can the threshold be larger than the subarray length?**
   - No, by definition, the threshold should be a valid count for the subarray length.

### Strategy:
The naive approach will be ineffective due to high query complexity, so we need to preprocess data to make queries efficient. We can use a combination of Mo's algorithm and a hash map/binary indexed tree to store and fetch frequency information efficiently.

1. **Preprocessing**: Use a hash map to store indices of occurrences for each element.
2. **Efficient Queries**:
   a. For each query, gather the elements and their frequencies in the given range using the preprocessed data.
   b. Check if any element appears at least `threshold` times.

### Code:
Here is a possible implementation using a combination of hash maps and binary search:

```cpp
#include <vector>
#include <unordered_map>
#include <algorithm>
#include <iostream>

using namespace std;

class MajorityChecker {
private:
    unordered_map<int, vector<int>> elementIndices;
    vector<int> arr;
    
public:
    MajorityChecker(vector<int>& arr) : arr(arr) {
        for(int i = 0; i < arr.size(); ++i) {
            elementIndices[arr[i]].push_back(i);
        }
    }
    
    int query(int left, int right, int threshold) {
        for(auto& elem : elementIndices) {
            vector<int>& indices = elem.second;
            if (indices.size() < threshold) continue;
            
            int leftPos = lower_bound(indices.begin(), indices.end(), left) - indices.begin();
            int rightPos = upper_bound(indices.begin(), indices.end(), right) - indices.begin();
            
            if (rightPos - leftPos >= threshold)
                return elem.first;
        }
        return -1;
    }
};

int main() {
    vector<int> arr = {1, 1, 2, 2, 1, 1};
    MajorityChecker majorityChecker(arr);
    cout << majorityChecker.query(0, 5, 4) << endl;  // Output should be 1
    cout << majorityChecker.query(0, 3, 3) << endl;  // Output should be -1
    cout << majorityChecker.query(2, 3, 2) << endl;  // Output should be 2
    return 0;
}
```

### Strategy Explanation:
1. **Preprocessing**:
   - Store indices of each element in a hash map. This helps in efficiently finding how many times an element appears within a specific range using binary search.

2. **Query Processing**:
   - For each query, check all elements that have enough occurrences to potentially be the majority element.
   - Use binary search (`lower_bound` and `upper_bound`) to determine the number of times an element appears within the given range.

### Time Complexity:
- **Preprocessing Time**: `O(n * log n)` where `n` is the size of the array.
- **Space Complexity**: `O(n)` for storing the indices of each element.
- **Query Time**: Each query runs in `O(k * log m)` where `k` is the number of unique elements with adequate occurrences and `m` is the average size of their occurrence lists. In the typical and best scenarios, this could be much faster due to the pruning of elements early based on frequency checks.


### Cut your prep time in half and DOMINATE your interview with [AlgoAdvance AI](https://algoAdvance.com)

- Got blindsided by a question you didn't expect?

- Spend too much time studying?

- Or simply don't have the time to go over all 3000 questions?

